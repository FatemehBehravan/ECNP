Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 100870
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 100870
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 100870
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 100870
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 100870
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 100870
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 100870
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 100870
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 100870
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 200710
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 200710
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 200710
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 200710
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 200710
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 200710
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 200710
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=5, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=2, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=130, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Num parameters: 200710
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=3)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=10, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=10, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=10, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=10, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=10, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=10, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=10, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=20000, num_epochs=10, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=200, num_epochs=10, test_1d_every=20, save_results_every=1, num_test_tasks=20, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=10, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=200, num_epochs=10, test_1d_every=20, save_results_every=1, num_test_tasks=20, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=10, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=200, num_epochs=10, test_1d_every=20, save_results_every=1, num_test_tasks=20, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=10, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=200, num_epochs=10, test_1d_every=20, save_results_every=1, num_test_tasks=20, max_context_points=50, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=10, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=200, num_epochs=10, test_1d_every=20, save_results_every=1, num_test_tasks=20, max_context_points=10, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=10, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=200, num_epochs=10, test_1d_every=20, save_results_every=1, num_test_tasks=20, max_context_points=10, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=10, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 199426
Namespace(dataset='XAUUSD', seed=0, training_iterations=200, num_epochs=10, test_1d_every=20, save_results_every=1, num_test_tasks=20, max_context_points=10, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=10, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_latent_encoder): ANPLatentEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_latent): ContextToLatentDistribution(
      (mean_layer): Linear(in_features=128, out_features=128, bias=True)
      (log_variance_layer): Linear(in_features=128, out_features=128, bias=True)
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 132866
Namespace(dataset='XAUUSD', seed=0, training_iterations=200, num_epochs=10, test_1d_every=20, save_results_every=1, num_test_tasks=20, max_context_points=10, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=10, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=False, use_latent_path=True, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 99842
Namespace(dataset='gp', seed=0, training_iterations=200, num_epochs=10, test_1d_every=20, save_results_every=1, num_test_tasks=20, max_context_points=10, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=10, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
ANPModel(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention(
      (linear_layers_list): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (linear_layers_list2): ModuleList(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Linear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (_latent_encoder): ANPLatentEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_latent): ContextToLatentDistribution(
      (mean_layer): Linear(in_features=128, out_features=128, bias=True)
      (log_variance_layer): Linear(in_features=128, out_features=128, bias=True)
    )
  )
  (_decoder): ANPDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=257, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=2, bias=True)
    )
  )
)
Num parameters: 315266
Namespace(dataset='XAUUSD', seed=0, training_iterations=200, num_epochs=10, test_1d_every=20, save_results_every=1, num_test_tasks=20, max_context_points=10, model_type='ANP', attention_type='multihead', gpu_id=0, epochs=10, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=True, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
Evd_det_model(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 132868
Namespace(dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
Evd_det_model(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 132868
Namespace(dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
Evd_det_model(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 132868
Namespace(dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
Evd_det_model(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 132868
Namespace(dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=150, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
Evd_det_model(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 132868
Namespace(dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=150, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
Evd_det_model(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 132868
Namespace(dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=150, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
Evd_det_model(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 132868
Namespace(dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=150, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
Evd_det_model(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 132868
Namespace(dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=150, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
Evd_det_model(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 132868
Namespace(dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=150, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
Evd_det_model(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 132868
Namespace(dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=150, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
Evd_det_model(
  (_deterministic_encoder): ANPDeterministicEncoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=128, bias=True)
    )
    (_attention): Attention()
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 132868
Namespace(dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 128, batch_first=True)
    (batch_norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc): Linear(in_features=128, out_features=128, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 150788
Namespace(input_size=2, lstm_layers=1, lstm_dropout=0.4, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 128, batch_first=True)
    (batch_norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc): Linear(in_features=128, out_features=128, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 150788
Namespace(input_size=2, lstm_layers=1, lstm_dropout=0.4, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 128, batch_first=True)
    (batch_norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc): Linear(in_features=128, out_features=128, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 150788
Namespace(input_size=2, lstm_layers=1, lstm_dropout=0.4, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5, channels=1)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 32, batch_first=True)
    (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc): Linear(in_features=32, out_features=32, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 72164
Namespace(input_size=2, lstm_layers=1, lstm_hidden_size=32, lstm_dropout=0.4, channels=1, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 32, batch_first=True)
    (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc): Linear(in_features=32, out_features=32, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 72164
Namespace(input_size=2, lstm_layers=1, lstm_hidden_size=32, lstm_dropout=0.4, channels=1, x_size=1, y_size=1, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 32, batch_first=True)
    (fc): Linear(in_features=32, out_features=32, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=129, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 72100
Namespace(input_size=2, lstm_layers=1, lstm_hidden_size=32, lstm_dropout=0.4, channels=1, x_size=1, y_size=1, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 32, batch_first=True)
    (fc): Linear(in_features=32, out_features=32, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=33, out_features=64, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 24740
Namespace(input_size=2, lstm_layers=1, lstm_hidden_size=32, lstm_dropout=0.4, channels=1, x_size=1, y_size=1, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 32, batch_first=True)
    (fc): Linear(in_features=32, out_features=32, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=33, out_features=64, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 24740
Namespace(input_size=2, lstm_layers=1, lstm_hidden_size=32, lstm_dropout=0.4, channels=1, x_size=1, y_size=1, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 32, batch_first=True)
    (fc): Linear(in_features=32, out_features=32, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=33, out_features=64, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 24740
Namespace(input_size=2, lstm_layers=1, lstm_hidden_size=32, lstm_dropout=0.4, channels=1, x_size=1, y_size=1, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=0.1, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 32, batch_first=True)
    (fc): Linear(in_features=32, out_features=32, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=33, out_features=64, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 24740
Namespace(input_size=2, lstm_layers=1, lstm_hidden_size=32, lstm_dropout=0.4, channels=1, x_size=1, y_size=1, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=1.0, nig_nll_ker_reg_coef=2.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 32, batch_first=True)
    (fc): Linear(in_features=32, out_features=32, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=33, out_features=64, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 24740
Namespace(input_size=2, lstm_layers=1, lstm_hidden_size=32, lstm_dropout=0.4, channels=1, x_size=1, y_size=1, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=2.0, nig_nll_ker_reg_coef=2.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 32, batch_first=True)
    (fc): Linear(in_features=32, out_features=32, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=33, out_features=64, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 24740
Namespace(input_size=2, lstm_layers=1, lstm_hidden_size=32, lstm_dropout=0.4, channels=1, x_size=1, y_size=1, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=2.0, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 32, batch_first=True)
    (fc): Linear(in_features=32, out_features=32, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=33, out_features=64, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 24740
Namespace(input_size=2, lstm_layers=1, lstm_hidden_size=32, lstm_dropout=0.4, channels=1, x_size=1, y_size=1, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=3.0, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5)
Saved Details
LSTM_Evd_Model(
  (_deterministic_encoder): LSTMModel(
    (lstm): LSTM(2, 32, batch_first=True)
    (fc): Linear(in_features=32, out_features=32, bias=True)
  )
  (_evidential_decoder): ANPEvidentialDecoder(
    (linear_layers_list): ModuleList(
      (0): Linear(in_features=33, out_features=64, bias=True)
    )
    (transform_gamma): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_v): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_alpha): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
    (transform_beta): Sequential(
      (0): ReLU()
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
Num parameters: 24740
Namespace(input_size=2, lstm_layers=1, lstm_hidden_size=32, lstm_dropout=0.4, channels=1, x_size=1, y_size=1, dataset='xauusd', seed=0, training_iterations=20000, num_epochs=50, test_1d_every=2000, save_results_every=1, num_test_tasks=2000, max_context_points=50, model_type='CNP', attention_type='multihead', gpu_id=0, epochs=50, batch_size=8, experiment_name='CNP-model-save-name', representation_size=128, hidden_size=128, num_enc_hdn_lrs=4, learning_rate=0.001, use_deterministic_path=True, use_latent_path=False, debugging=False, load_model=False, nig_nll_reg_coef=1.0, nig_nll_ker_reg_coef=1.0, ev_dec_beta_min=0.2, ev_dec_alpha_max=20.0, ev_dec_v_max=20.0, ev_lat_beta_min=0.2, ev_lat_alpha_max=20.0, ev_lat_v_max=20.0, outlier_training_tasks='False', outlier_val=0.0, active_task_sel=False, use_domain_knowledge=False, save_models_every=5)
